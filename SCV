#Ngô Hoàng Ân -B1709524
import numpy as np
from sklearn.svm import SVC

X1 = [[1,3], [3,3], [4,0], [3,0], [2, 2]]
y1 = [1, 1, 1, 1, 1]
X2 = [[0,0], [1,1], [1,2], [2,0]]
y2 = [-1, -1, -1, -1]
X = np.array(X1 + X2)
y = y1 + y2

clf = SVC(kernel='linear', C=1E10)
clf.fit(X, y)
print (clf.support_vectors_)
import matplotlib.pyplot as plt

def plot_svc_decision_function(clf, ax=None, plot_support=True): 
    if ax is None:
        ax = plt.gca()
    xlim = ax.get_xlim()
    ylim = ax.get_ylim()
    x = np.linspace(xlim[0], xlim[1], 30)
    y = np.linspace(ylim[0], ylim[1], 30)
    Y, X = np.meshgrid(y, x)
    xy = np.vstack([X.ravel(), Y.ravel()]).T
    P = clf.decision_function(xy).reshape(X.shape)
    ax.contour(X, Y, P, colors='k',
               levels=[-1, 0, 1], alpha=0.5,
               linestyles=['--', '-', '--'])
    if plot_support:
        ax.scatter(clf.support_vectors_[:, 0],clf.support_vectors_[:, 1],s=300, linewidth=1, facecolors='none');
    ax.set_xlim(xlim)
    ax.set_ylim(ylim)

plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='brg');
plot_svc_decision_function(clf)
#plt.show()
from sklearn.model_selection import GridSearchCV
parameter_candidates = [{'C': [0.001, 0.01, 0.1, 1, 5, 10, 100, 1000], 'kernel': ['linear']},]

clf = GridSearchCV(estimator=SVC(), param_grid=parameter_candidates, n_jobs=-1)
clf.fit(X, y)
print('Best score:', clf.best_score_)
print('Best C:',clf.best_estimator_.C)
import pandas as pd
from sklearn import datasets
iris = datasets.load_iris()
columns=["Petal Length","Petal Width","Sepal Length","Sepal Width"];
m = pd.DataFrame(iris.data, columns=columns)
n = iris.target
cla = SVC(kernel='linear', C=1E10)
cla.fit(m, n)
print (cla.support_vectors_)
m = np.array(m)
from sklearn.model_selection import GridSearchCV
parameter_candidates = [{'C': [0.001, 0.01, 0.1, 1, 5, 10, 100, 1000], 'kernel': ['linear']},]
cla = GridSearchCV(estimator=SVC(), param_grid=parameter_candidates, n_jobs=-1)
cla.fit(m, n)
print('Best score:', cla.best_score_)
print('Best C:',cla.best_estimator_.C)
